{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4de373e",
   "metadata": {},
   "source": [
    "## **READ BEFORE PROCEEDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ff52a",
   "metadata": {},
   "source": [
    "- Inside the `input` and `output` directories, make sure you create a directory for each phenotype you plan on executing the ChatGPT code for\n",
    "- You will need to upload the files generated by ATLAS into the appropriate directory and name them according to the filenames specified in the first code block for each phenotype of interest\n",
    "- Create an OpenAI account, generate an OpenAI API key (you may need to deposit a small API balance to use the key), and paste the API key in the .env file located so that ChatGPT responses can be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d601d17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q openai\n",
    "!{sys.executable} -m pip install -q python-dotenv\n",
    "!{sys.executable} -m pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963beded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./myenv/lib/python3.11/site-packages (1.20.0)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/58/8d/e92a2f37249ceedd439d4770446cb89db2a94f22a44682a0515ddedcbe35/openai-1.31.2-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.31.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./myenv/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./myenv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./myenv/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./myenv/lib/python3.11/site-packages (from openai) (2.7.0)\n",
      "Requirement already satisfied: sniffio in ./myenv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./myenv/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./myenv/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./myenv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./myenv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./myenv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
      "Downloading openai-1.31.2-py3-none-any.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.20.0\n",
      "    Uninstalling openai-1.20.0:\n",
      "      Successfully uninstalled openai-1.20.0\n",
      "Successfully installed openai-1.31.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f74106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aad3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load API key from ENV file and get properties of interest\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "#Instantiate OpenAI client\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27190eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(disease, diseaseDescription, conceptName, domainDefinition, domain = \"condition\"):\n",
    "    prompt = f\"\"\"You are a helpful medical expert. Your task is to assess whether an inputted {domain} is specific to an inputted malady. Specific means that if you have the {domain}, then you definitely have the malady, but if you have the malady, you may or may not have the {domain}.\n",
    "\n",
    "A {domain} should be considered {domainDefinition}. \n",
    "\n",
    "A description of the malady is provided to assist you, but please use your extensive medical knowledge in addition to this description when performing the task at hand. Provide a “yes” or “no” answer, and explain your rationale for the answer you provide.\n",
    "\n",
    "Here is the malady:\n",
    "{disease}\n",
    "\n",
    "Here is a brief description of the malady:\n",
    "{diseaseDescription}\n",
    "\n",
    "Here is the condition:\n",
    "{conceptName}\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb126baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_response(content:str, print_output=False)->str:\n",
    "    modelName = \"gpt-4o\"\n",
    "    completions = client.chat.completions.create(#A method that allows you to generate text-based chatbot responses using a pre-trained GPT language model.\n",
    "        model = modelName, \n",
    "        temperature = 0, #controls the level of randomness or creativity in the generated text; . A higher temperature value will result in a more diverse and creative output, as it increases the probability of sampling lower probability tokens. \n",
    "#         max_tokens = 2000, #controls the maximum number of tokens (words or subwords) in the generated text.\n",
    "#         stop = ['###'], #specifies a sequence of tokens that the GPT model should stop generating text when it encounters\n",
    "        n = 1, #the number of possible chat completions or responses that the GPT model should generate in response to a given prompt\n",
    "        messages=[\n",
    "          {\"role\":\"user\", \"content\": content},\n",
    "          ])\n",
    "\n",
    "    # Displaying the output can be helpful if things go wrong\n",
    "    if print_output:\n",
    "        print(completions)\n",
    "\n",
    "    # Return the first choice's text\n",
    "    ##return completions.choices[0]['message']['content'] #I only want the first repsonses\n",
    "    return completions.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecf1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(response:str):\n",
    "    outputDict = dict()\n",
    "    if bool(re.match(\"yes\", response, re.I)):\n",
    "        outputDict[\"include\"] = True\n",
    "    else:\n",
    "        outputDict[\"include\"] = False\n",
    "    outputDict[\"rationale\"] = response\n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96d4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formula to compute the sensitivity of proposed concept set\n",
    "def compute_sens_and_spec(goldStandardPositives:list, goldStandardNegatives:list, proposedPositives:list, proposedNegatives:list)->float:\n",
    "    #Convert string elements to numeric elements\n",
    "    proposedPositives  = list(map(int, proposedPositives))\n",
    "    proposedNegatives  = list(map(int, proposedNegatives))\n",
    "    #Initialize variables\n",
    "    truePositivesArr = sorted(set(proposedPositives).intersection(goldStandardPositives))\n",
    "    truePositiveCount = len(truePositivesArr)\n",
    "    falseNegativesArr = sorted(set(proposedNegatives).intersection(goldStandardPositives))\n",
    "    falseNegativeCount = len(falseNegativesArr)\n",
    "    trueNegativesArr = sorted(set(proposedNegatives).intersection(goldStandardNegatives))\n",
    "    trueNegativeCount = len(trueNegativesArr)\n",
    "    falsePositivesArr = sorted(set(proposedPositives).intersection(goldStandardNegatives))\n",
    "    falsePositiveCount = len(falsePositivesArr)\n",
    "    #Initialize dictionary to return      \n",
    "    returnValuesDict = dict()\n",
    "    #Avoid division by 0 exception\n",
    "    if (truePositiveCount+falseNegativeCount) == 0:\n",
    "        returnValuesDict[\"sensitivity\"] = 0\n",
    "    else:\n",
    "        returnValuesDict[\"sensitivity\"] = truePositiveCount/(truePositiveCount + falseNegativeCount)\n",
    "    returnValuesDict[\"truePositives\"] = truePositivesArr\n",
    "    returnValuesDict[\"falseNegatives\"] = falseNegativesArr\n",
    "    if (trueNegativeCount + falsePositiveCount) == 0:\n",
    "        returnValuesDict[\"specificity\"] = 0\n",
    "    else:\n",
    "        returnValuesDict[\"specificity\"] = trueNegativeCount/(trueNegativeCount + falsePositiveCount)\n",
    "    returnValuesDict[\"trueNegatives\"] = trueNegativesArr\n",
    "    returnValuesDict[\"falsePositives\"] = falsePositivesArr\n",
    "    return returnValuesDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca592156",
   "metadata": {},
   "source": [
    "## Type 1 Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637a84c",
   "metadata": {},
   "source": [
    "Initialize filepath variables to avoid hardcoding, variables related to the GPT prompt, and any DataFrames needed for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ed5cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/Type1Diabetes/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/Type1Diabetes/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/Type1Diabetes/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/Type1Diabetes/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/Type1Diabetes/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/Type1Diabetes/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/Type1Diabetes/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/Type1Diabetes/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/Type1Diabetes/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/Type1Diabetes/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/Type1Diabetes/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Type 1 Diabetes Mellitus\"\n",
    "diabetesDescription = \"Type 1 Diabetes Mellitus (T1DM) is a chronic autoimmune disorder characterized by the destruction of insulin-producing beta cells in the pancreas, leading to absolute insulin deficiency. It is defined as a metabolic disorder characterized by hyperglycemia due to insulin deficiency resulting from autoimmune destruction of pancreatic beta cells. T1DM typically presents with polyuria, polydipsia, polyphagia, weight loss, and fatigue. Diagnosis is confirmed by elevated blood glucose levels, presence of autoantibodies against pancreatic beta cells, and often necessitates lifelong insulin replacement therapy. Management involves a multidisciplinary approach focusing on insulin therapy, dietary modifications, regular exercise, and monitoring blood glucose levels. Prognosis varies, with complications including diabetic ketoacidosis (DKA), cardiovascular disease, neuropathy, nephropathy, and retinopathy. Exclusions for T1DM include other types of diabetes such as type 2 diabetes mellitus and secondary causes of hyperglycemia (pregnancy, disorders of pancreas, alcohol dependency, etc.).\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"Id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40747e8",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a24aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diabetesDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab374890",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f124a",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b89b68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diabetesDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ed5f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2967c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "t1dmRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", t1dmRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", t1dmRes[\"specificity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029c864",
   "metadata": {},
   "source": [
    "## Acute Myocardial Infarction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "978442e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/AcuteMyocardialInfarction/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/AcuteMyocardialInfarction/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/AcuteMyocardialInfarction/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/AcuteMyocardialInfarction/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/AcuteMyocardialInfarction/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/AcuteMyocardialInfarction/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/AcuteMyocardialInfarction/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/AcuteMyocardialInfarction/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/AcuteMyocardialInfarction/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/AcuteMyocardialInfarction/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/AcuteMyocardialInfarction/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Acute Myocardial Infarction\"\n",
    "diseaseDescription = \"Acute myocardial infarction (AMI), commonly known as a heart attack, is a life-threatening medical emergency characterized by the sudden occlusion of a coronary artery, resulting in ischemia and necrosis of cardiac tissue. It is defined as the abrupt interruption of blood flow to a portion of the myocardium, leading to myocardial cell death and subsequent release of cardiac biomarkers such as troponin. AMI typically presents with severe chest pain or pressure, often radiating to the left arm, jaw, or back, along with accompanying symptoms such as shortness of breath, diaphoresis, nausea, and vomiting. Diagnosis is confirmed by clinical history, electrocardiography (ECG) findings indicative of ST-segment elevation or new-onset Q waves, and elevated cardiac biomarkers. Treatment involves immediate reperfusion therapy to restore blood flow to the ischemic myocardium, utilizing thrombolytics or percutaneous coronary intervention (PCI). Additional therapies include antiplatelet agents, anticoagulants, beta-blockers, angiotensin-converting enzyme (ACE) inhibitors, and statins to prevent recurrent ischemic events and reduce mortality. Prognosis varies depending on the extent of myocardial damage, timely intervention, and the presence of comorbidities. Exclusions for AMI include other causes of acute chest pain such as unstable angina, aortic dissection, and pulmonary embolism.\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c531d",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c52636c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_sync/http11.py:93\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     92\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_sync/http11.py:151\u001b[0m, in \u001b[0;36mHTTP11Connection._send_request_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    149\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 151\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mh11\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLocalProtocolError\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLocalProtocolError\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh11\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:951\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 951\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_transports/default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m dfConcepts\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m generate_prompt(conceptName \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m], disease \u001b[38;5;241m=\u001b[39m disease, diseaseDescription \u001b[38;5;241m=\u001b[39m diseaseDescription, domain \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m, domainDefinition \u001b[38;5;241m=\u001b[39m conditionDefinition)\n\u001b[0;32m----> 3\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_gpt_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     answerComponents \u001b[38;5;241m=\u001b[39m parse_output(res)\n\u001b[1;32m      5\u001b[0m     dfResponses\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(dfResponses\u001b[38;5;241m.\u001b[39mindex)] \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m\"\u001b[39m], answerComponents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m], answerComponents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrationale\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mgenerate_gpt_response\u001b[0;34m(content, print_output)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_gpt_response\u001b[39m(content:\u001b[38;5;28mstr\u001b[39m, print_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m     modelName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     completions \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;66;43;03m#A method that allows you to generate text-based chatbot responses using a pre-trained GPT language model.\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodelName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#controls the level of randomness or creativity in the generated text; . A higher temperature value will result in a more diverse and creative output, as it increases the probability of sampling lower probability tokens. \u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;43;03m#         max_tokens = 2000, #controls the maximum number of tokens (words or subwords) in the generated text.\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;43;03m#         stop = ['###'], #specifies a sequence of tokens that the GPT model should stop generating text when it encounters\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#the number of possible chat completions or responses that the GPT model should generate in response to a given prompt\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Displaying the output can be helpful if things go wrong\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_output:\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/resources/chat/completions.py:581\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    580\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:1233\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1221\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1229\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1230\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1231\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1232\u001b[0m     )\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:922\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    915\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    921\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:975\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    972\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:975\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    972\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages/openai/_base_client.py:985\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    976\u001b[0m             options,\n\u001b[1;32m    977\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    981\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    982\u001b[0m         )\n\u001b[1;32m    984\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase\n\u001b[1;32m    989\u001b[0m )\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bb39edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f709c",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f1cb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ea900f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "28388ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8648648648648649\n",
      "Specificity:  0.4810126582278481\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "amiRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", amiRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", amiRes[\"specificity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b7eb9",
   "metadata": {},
   "source": [
    "## Rheumatoid Arthritis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0658a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/RheumatoidArthritis/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/RheumatoidArthritis/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/RheumatoidArthritis/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/RheumatoidArthritis/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/RheumatoidArthritis/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/RheumatoidArthritis/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/RheumatoidArthritis/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/RheumatoidArthritis/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/RheumatoidArthritis/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/RheumatoidArthritis/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/RheumatoidArthritis/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Rheumatoid Arthritis\"\n",
    "diseaseDescription = \"Rheumatoid Arthritis (RA) is a chronic autoimmune inflammatory disorder primarily affecting the synovial joints. It is defined as a systemic autoimmune disease characterized by symmetric polyarthritis with joint swelling, tenderness, and destruction, leading to deformities and functional impairment. RA often presents with morning stiffness, joint pain, and swelling, particularly in the small joints of the hands and feet. Diagnosis is based on clinical criteria such as joint involvement, serological markers (e.g., rheumatoid factor, anti-cyclic citrullinated peptide antibodies), and imaging findings (e.g., joint erosions on X-ray). Treatment aims to control inflammation, relieve symptoms, and prevent joint damage, utilizing disease-modifying antirheumatic drugs (DMARDs), biologic agents, nonsteroidal anti-inflammatory drugs (NSAIDs), and glucocorticoids. Prognosis varies widely, with some patients achieving remission while others experience progressive joint damage and disability. Exclusions for RA include other forms of arthritis such as osteoarthritis and systemic lupus erythematosus (SLE).\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c0766",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "722dab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ba05d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b16b0b",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fcc05ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1c366dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a5e82da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  1.0\n",
      "Specificity:  0.49242424242424243\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "raRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", raRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", raRes[\"specificity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2a0d4",
   "metadata": {},
   "source": [
    "## Pulmonary Hypertension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1319b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/PulmonaryHypertension/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/PulmonaryHypertension/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/PulmonaryHypertension/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/PulmonaryHypertension/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/PulmonaryHypertension/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/PulmonaryHypertension/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/PulmonaryHypertension/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/PulmonaryHypertension/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/PulmonaryHypertension/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/PulmonaryHypertension/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/PulmonaryHypertension/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Pulmonary Hypertension\"\n",
    "diseaseDescription = \"Pulmonary Hypertension (PH) is a complex and progressive condition characterized by elevated blood pressure within the pulmonary vasculature, leading to right ventricular dysfunction and ultimately, heart failure. It is defined as a hemodynamic and pathophysiological state characterized by an increase in mean pulmonary arterial pressure (mPAP) greater than or equal to 20 mmHg at rest, as assessed by right heart catheterization. PH can result from various etiologies, including idiopathic, heritable, drug-induced, and associated with other conditions such as connective tissue diseases, congenital heart defects, or chronic lung diseases. Patients with PH may present with symptoms such as dyspnea, fatigue, chest pain, syncope, and signs of right heart failure. Diagnostic evaluation involves a thorough clinical assessment, echocardiography, pulmonary function tests, and right heart catheterization to confirm the diagnosis and assess disease severity. Treatment aims to improve symptoms, slow disease progression, and optimize hemodynamics, utilizing various classes of medications including vasodilators, endothelin receptor antagonists, phosphodiesterase-5 inhibitors, soluble guanylate cyclase stimulators, and prostacyclin analogs. Prognosis varies depending on the underlying cause and severity of PH, with early diagnosis and targeted therapy improving outcomes. Exclusions for PH include other causes of pulmonary arterial hypertension such as left heart disease, chronic thromboembolic disease, and pulmonary arterial hypertension associated with lung diseases and/or hypoxia.\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d54c1",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "18244667",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2d68d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02870e4",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67d678e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    dfResponses.loc[len(dfResponses.index)] = [row[\"Name\"], row[\"Id\"], answerComponents[\"include\"], answerComponents[\"rationale\"]]\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b484b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "58aa506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0\n",
      "Specificity:  0.6486486486486487\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "phRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", phRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", phRes[\"specificity\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
