{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4de373e",
   "metadata": {},
   "source": [
    "## **READ BEFORE PROCEEDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ff52a",
   "metadata": {},
   "source": [
    "- Inside the `input` and `output` directories, make sure you create a directory for each phenotype you plan on executing the ChatGPT code for\n",
    "- You will need to upload the files generated by ATLAS into the appropriate directory and name them according to the filenames specified in the first code block for each phenotype of interest\n",
    "- Create an OpenAI account, generate an OpenAI API key (you may need to deposit a small API balance to use the key), and paste the API key in the .env file located so that ChatGPT responses can be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d601d17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q openai\n",
    "!{sys.executable} -m pip install -q python-dotenv\n",
    "!{sys.executable} -m pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963beded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (1.31.2)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/11/e0/4ddc922d454cc96dcdbc1c0b64fb886b8633fbe470b6e4c749dce06ab6fa/openai-1.32.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.32.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (2.7.0)\n",
      "Requirement already satisfied: sniffio in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Users/ara2205/hripcsak-lab/rotation-project/myenv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
      "Downloading openai-1.32.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.31.2\n",
      "    Uninstalling openai-1.31.2:\n",
      "      Successfully uninstalled openai-1.31.2\n",
      "Successfully installed openai-1.32.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f74106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aad3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load API key from ENV file and get properties of interest\n",
    "OPENAI_API_KEY = \"ENTER API KEY HERE\"\n",
    "#Instantiate OpenAI client\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27190eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(disease, diseaseDescription, conceptName, domainDefinition, domain = \"condition\"):\n",
    "    prompt = f\"\"\"You are a helpful medical expert. Your task is to assess whether an inputted {domain} is specific to an inputted malady. Specific means that if you have the {domain}, then you definitely have the malady, but if you have the malady, you may or may not have the {domain}.\n",
    "\n",
    "A {domain} should be considered {domainDefinition}. \n",
    "\n",
    "A description of the malady is provided to assist you, but please use your extensive medical knowledge in addition to this description when performing the task at hand. Provide a “yes” or “no” answer, and explain your rationale for the answer you provide.\n",
    "\n",
    "Here is the malady:\n",
    "{disease}\n",
    "\n",
    "Here is a brief description of the malady:\n",
    "{diseaseDescription}\n",
    "\n",
    "Here is the condition:\n",
    "{conceptName}\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb126baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_response(content:str, print_output=False)->str:\n",
    "    modelName = \"gpt-3.5-turbo\"\n",
    "    completions = client.chat.completions.create(#A method that allows you to generate text-based chatbot responses using a pre-trained GPT language model.\n",
    "        model = modelName, \n",
    "        temperature = 0, #controls the level of randomness or creativity in the generated text; . A higher temperature value will result in a more diverse and creative output, as it increases the probability of sampling lower probability tokens. \n",
    "#         max_tokens = 2000, #controls the maximum number of tokens (words or subwords) in the generated text.\n",
    "#         stop = ['###'], #specifies a sequence of tokens that the GPT model should stop generating text when it encounters\n",
    "        n = 1, #the number of possible chat completions or responses that the GPT model should generate in response to a given prompt\n",
    "        messages=[\n",
    "          {\"role\":\"user\", \"content\": content},\n",
    "          ])\n",
    "\n",
    "    # Displaying the output can be helpful if things go wrong\n",
    "    if print_output:\n",
    "        print(completions)\n",
    "\n",
    "    # Return the first choice's text\n",
    "    ##return completions.choices[0]['message']['content'] #I only want the first repsonses\n",
    "    return completions.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eecf1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(response:str):\n",
    "    outputDict = dict()\n",
    "    if bool(re.match(\"yes\", response, re.I)):\n",
    "        outputDict[\"include\"] = True\n",
    "    else:\n",
    "        outputDict[\"include\"] = False\n",
    "    outputDict[\"rationale\"] = response\n",
    "    return outputDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96d4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formula to compute the sensitivity of proposed concept set\n",
    "def compute_sens_and_spec(goldStandardPositives:list, goldStandardNegatives:list, proposedPositives:list, proposedNegatives:list)->float:\n",
    "    #Convert string elements to numeric elements\n",
    "    proposedPositives  = list(map(int, proposedPositives))\n",
    "    proposedNegatives  = list(map(int, proposedNegatives))\n",
    "    #Initialize variables\n",
    "    truePositivesArr = sorted(set(proposedPositives).intersection(goldStandardPositives))\n",
    "    truePositiveCount = len(truePositivesArr)\n",
    "    falseNegativesArr = sorted(set(proposedNegatives).intersection(goldStandardPositives))\n",
    "    falseNegativeCount = len(falseNegativesArr)\n",
    "    trueNegativesArr = sorted(set(proposedNegatives).intersection(goldStandardNegatives))\n",
    "    trueNegativeCount = len(trueNegativesArr)\n",
    "    falsePositivesArr = sorted(set(proposedPositives).intersection(goldStandardNegatives))\n",
    "    falsePositiveCount = len(falsePositivesArr)\n",
    "    #Initialize dictionary to return      \n",
    "    returnValuesDict = dict()\n",
    "    #Avoid division by 0 exception\n",
    "    if (truePositiveCount+falseNegativeCount) == 0:\n",
    "        returnValuesDict[\"sensitivity\"] = 0\n",
    "    else:\n",
    "        returnValuesDict[\"sensitivity\"] = truePositiveCount/(truePositiveCount + falseNegativeCount)\n",
    "    returnValuesDict[\"truePositives\"] = truePositivesArr\n",
    "    returnValuesDict[\"falseNegatives\"] = falseNegativesArr\n",
    "    if (trueNegativeCount + falsePositiveCount) == 0:\n",
    "        returnValuesDict[\"specificity\"] = 0\n",
    "    else:\n",
    "        returnValuesDict[\"specificity\"] = trueNegativeCount/(trueNegativeCount + falsePositiveCount)\n",
    "    returnValuesDict[\"trueNegatives\"] = trueNegativesArr\n",
    "    returnValuesDict[\"falsePositives\"] = falsePositivesArr\n",
    "    return returnValuesDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca592156",
   "metadata": {},
   "source": [
    "## Type 1 Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637a84c",
   "metadata": {},
   "source": [
    "Initialize filepath variables to avoid hardcoding, variables related to the GPT prompt, and any DataFrames needed for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed5cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/Type1Diabetes/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/Type1Diabetes/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/Type1Diabetes/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/Type1Diabetes/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/Type1Diabetes/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/Type1Diabetes/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/Type1Diabetes/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/Type1Diabetes/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/Type1Diabetes/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/Type1Diabetes/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/Type1Diabetes/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Type 1 Diabetes Mellitus\"\n",
    "diseaseDescription = \"Type 1 Diabetes Mellitus (T1DM) is a chronic autoimmune disorder characterized by the destruction of insulin-producing beta cells in the pancreas, leading to absolute insulin deficiency. It is defined as a metabolic disorder characterized by hyperglycemia due to insulin deficiency resulting from autoimmune destruction of pancreatic beta cells. T1DM typically presents with polyuria, polydipsia, polyphagia, weight loss, and fatigue. Diagnosis is confirmed by elevated blood glucose levels, presence of autoantibodies against pancreatic beta cells, and often necessitates lifelong insulin replacement therapy. Management involves a multidisciplinary approach focusing on insulin therapy, dietary modifications, regular exercise, and monitoring blood glucose levels. Prognosis varies, with complications including diabetic ketoacidosis (DKA), cardiovascular disease, neuropathy, nephropathy, and retinopathy. Exclusions for T1DM include other types of diabetes such as type 2 diabetes mellitus and secondary causes of hyperglycemia (pregnancy, disorders of pancreas, alcohol dependency, etc.).\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40747e8",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a24aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab374890",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f124a",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b89b68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed5f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2967c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.9529411764705882\n",
      "Specificity:  0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedPositiveConcepts = list(filter(None, proposedPositiveConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedPositiveConcepts = list(set(proposedPositiveConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedNegativeConcepts = list(filter(None, proposedNegativeConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedNegativeConcepts = list(set(proposedNegativeConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "t1dmRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", t1dmRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", t1dmRes[\"specificity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029c864",
   "metadata": {},
   "source": [
    "## Acute Myocardial Infarction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "978442e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/AcuteMyocardialInfarction/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/AcuteMyocardialInfarction/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/AcuteMyocardialInfarction/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/AcuteMyocardialInfarction/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/AcuteMyocardialInfarction/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/AcuteMyocardialInfarction/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/AcuteMyocardialInfarction/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/AcuteMyocardialInfarction/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/AcuteMyocardialInfarction/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/AcuteMyocardialInfarction/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/AcuteMyocardialInfarction/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Acute Myocardial Infarction\"\n",
    "diseaseDescription = \"Acute myocardial infarction (AMI), commonly known as a heart attack, is a life-threatening medical emergency characterized by the sudden occlusion of a coronary artery, resulting in ischemia and necrosis of cardiac tissue. It is defined as the abrupt interruption of blood flow to a portion of the myocardium, leading to myocardial cell death and subsequent release of cardiac biomarkers such as troponin. AMI typically presents with severe chest pain or pressure, often radiating to the left arm, jaw, or back, along with accompanying symptoms such as shortness of breath, diaphoresis, nausea, and vomiting. Diagnosis is confirmed by clinical history, electrocardiography (ECG) findings indicative of ST-segment elevation or new-onset Q waves, and elevated cardiac biomarkers. Treatment involves immediate reperfusion therapy to restore blood flow to the ischemic myocardium, utilizing thrombolytics or percutaneous coronary intervention (PCI). Additional therapies include antiplatelet agents, anticoagulants, beta-blockers, angiotensin-converting enzyme (ACE) inhibitors, and statins to prevent recurrent ischemic events and reduce mortality. Prognosis varies depending on the extent of myocardial damage, timely intervention, and the presence of comorbidities. Exclusions for AMI include other causes of acute chest pain such as unstable angina, aortic dissection, and pulmonary embolism.\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c531d",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52636c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb39edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f709c",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f1cb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea900f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28388ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.8787878787878788\n",
      "Specificity:  0.4794520547945205\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedPositiveConcepts = list(filter(None, proposedPositiveConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedPositiveConcepts = list(set(proposedPositiveConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedNegativeConcepts = list(filter(None, proposedNegativeConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedNegativeConcepts = list(set(proposedNegativeConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "amiRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", amiRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", amiRes[\"specificity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b7eb9",
   "metadata": {},
   "source": [
    "## Rheumatoid Arthritis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0658a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/RheumatoidArthritis/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/RheumatoidArthritis/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/RheumatoidArthritis/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/RheumatoidArthritis/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/RheumatoidArthritis/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/RheumatoidArthritis/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/RheumatoidArthritis/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/RheumatoidArthritis/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/RheumatoidArthritis/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/RheumatoidArthritis/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/RheumatoidArthritis/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Rheumatoid Arthritis\"\n",
    "diseaseDescription = \"Rheumatoid Arthritis (RA) is a chronic autoimmune inflammatory disorder primarily affecting the synovial joints. It is defined as a systemic autoimmune disease characterized by symmetric polyarthritis with joint swelling, tenderness, and destruction, leading to deformities and functional impairment. RA often presents with morning stiffness, joint pain, and swelling, particularly in the small joints of the hands and feet. Diagnosis is based on clinical criteria such as joint involvement, serological markers (e.g., rheumatoid factor, anti-cyclic citrullinated peptide antibodies), and imaging findings (e.g., joint erosions on X-ray). Treatment aims to control inflammation, relieve symptoms, and prevent joint damage, utilizing disease-modifying antirheumatic drugs (DMARDs), biologic agents, nonsteroidal anti-inflammatory drugs (NSAIDs), and glucocorticoids. Prognosis varies widely, with some patients achieving remission while others experience progressive joint damage and disability. Exclusions for RA include other forms of arthritis such as osteoarthritis and systemic lupus erythematosus (SLE).\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c0766",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "722dab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba05d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b16b0b",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc05ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c366dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a5e82da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.9411764705882353\n",
      "Specificity:  0.4298245614035088\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedPositiveConcepts = list(filter(None, proposedPositiveConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedPositiveConcepts = list(set(proposedPositiveConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedNegativeConcepts = list(filter(None, proposedNegativeConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedNegativeConcepts = list(set(proposedNegativeConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "raRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", raRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", raRes[\"specificity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2a0d4",
   "metadata": {},
   "source": [
    "## Pulmonary Hypertension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1319b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define filepath variables\n",
    "phoebePassOneFilepath = \"input/PulmonaryHypertension/phoebe_concepts_pass_one.csv\"\n",
    "phoebePassTwoFilepath = \"input/PulmonaryHypertension/phoebe_concepts_pass_two.csv\"\n",
    "gptAnswersPassOneFilepath = \"output/PulmonaryHypertension/gpt_answers_pass_one.csv\"\n",
    "gptPositivesPassOneFilepath = \"output/PulmonaryHypertension/gpt_positives_pass_one.txt\"\n",
    "gptNegativesPassOneFilepath = \"output/PulmonaryHypertension/gpt_negatives_pass_one.txt\"\n",
    "gptAnswersPassTwoFilepath = \"output/PulmonaryHypertension/gpt_answers_pass_two.csv\"\n",
    "gptPositivesPassTwoFilepath = \"output/PulmonaryHypertension/gpt_positives_pass_two.txt\"\n",
    "gptNegativesPassTwoFilepath = \"output/PulmonaryHypertension/gpt_negatives_pass_two.txt\"\n",
    "gptFinalFilepath = \"output/PulmonaryHypertension/gpt_concepts_finals.csv\"\n",
    "goldStandardPositivesFilepath = \"input/PulmonaryHypertension/gold_standard_positive_concepts.csv\"\n",
    "goldStandardNegativesFilepath = \"input/PulmonaryHypertension/gold_standard_negative_concepts.csv\"\n",
    "#Define ChatGPT prompt information \n",
    "disease = \"Pulmonary Hypertension\"\n",
    "diseaseDescription = \"Pulmonary Hypertension (PH) is a complex and progressive condition characterized by elevated blood pressure within the pulmonary vasculature, leading to right ventricular dysfunction and ultimately, heart failure. It is defined as a hemodynamic and pathophysiological state characterized by an increase in mean pulmonary arterial pressure (mPAP) greater than or equal to 20 mmHg at rest, as assessed by right heart catheterization. PH can result from various etiologies, including idiopathic, heritable, drug-induced, and associated with other conditions such as connective tissue diseases, congenital heart defects, or chronic lung diseases. Patients with PH may present with symptoms such as dyspnea, fatigue, chest pain, syncope, and signs of right heart failure. Diagnostic evaluation involves a thorough clinical assessment, echocardiography, pulmonary function tests, and right heart catheterization to confirm the diagnosis and assess disease severity. Treatment aims to improve symptoms, slow disease progression, and optimize hemodynamics, utilizing various classes of medications including vasodilators, endothelin receptor antagonists, phosphodiesterase-5 inhibitors, soluble guanylate cyclase stimulators, and prostacyclin analogs. Prognosis varies depending on the underlying cause and severity of PH, with early diagnosis and targeted therapy improving outcomes. Exclusions for PH include other causes of pulmonary arterial hypertension such as left heart disease, chronic thromboembolic disease, and pulmonary arterial hypertension associated with lung diseases and/or hypoxia.\"\n",
    "domain = \"condition\"\n",
    "conditionDefinition = \"records of events of a person suggesting the presence of a disease or medical condition stated as a diagnosis, a sign, or a symptom, which is either observed by a provider or reported by the patient\"\n",
    "#Initialize dataframes\n",
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassOneFilepath)\n",
    "#Load gold-standard concept sets\n",
    "dfGoldStandardPositives = pd.read_csv(goldStandardPositivesFilepath)\n",
    "goldStandardPositives = dfGoldStandardPositives[\"concept_id\"].tolist()\n",
    "dfGoldStandardNegatives = pd.read_csv(goldStandardNegativesFilepath)\n",
    "goldStandardNegatives = dfGoldStandardNegatives[\"concept_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d54c1",
   "metadata": {},
   "source": [
    "### ChatGPT Pass One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18244667",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassOneFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d68d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassOneFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassOneFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02870e4",
   "metadata": {},
   "source": [
    "### ChatGPT Pass Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67d678e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResponses = pd.DataFrame(columns = [\"concept_name\", \"concept_id\", \"include\", \"rationale\"])\n",
    "dfConcepts = pd.read_csv(phoebePassTwoFilepath)\n",
    "for index, row in dfConcepts.iterrows():\n",
    "    prompt = generate_prompt(conceptName = row[\"Name\"], disease = disease, diseaseDescription = diseaseDescription, domain = \"condition\", domainDefinition = conditionDefinition)\n",
    "    res = generate_gpt_response(prompt)\n",
    "    answerComponents = parse_output(res)\n",
    "    newRow = {\"concept_name\": [row[\"Name\"]], \"concept_id\": [row[\"Id\"]], \"include\": [answerComponents[\"include\"]], \"rationale\": [answerComponents[\"rationale\"]]}\n",
    "    dfNew = pd.DataFrame(newRow)\n",
    "    dfResponses = pd.concat([dfResponses, dfNew], ignore_index = True)\n",
    "dfResponses = dfResponses.drop_duplicates()\n",
    "dfResponses.to_csv(gptAnswersPassTwoFilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b484b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptPositivesMask = dfResponses[\"include\"] == True \n",
    "gptNegativesMask = dfResponses[\"include\"] == False\n",
    "dfPositives = dfResponses[gptPositivesMask]\n",
    "dfNegatives = dfResponses[gptNegativesMask]\n",
    "positiveConcepts = dfPositives[\"concept_id\"].tolist()\n",
    "negativeConcepts = dfNegatives[\"concept_id\"].tolist()\n",
    "positiveConceptsAsStr = \"\"\n",
    "negativeConceptsAsStr = \"\"\n",
    "for el in positiveConcepts:\n",
    "    positiveConceptsAsStr += (str(el) + \",\")\n",
    "for el in negativeConcepts:\n",
    "    negativeConceptsAsStr += (str(el) + \",\")\n",
    "fp = open(gptPositivesPassTwoFilepath, \"x\")\n",
    "fp.write(positiveConceptsAsStr[:len(positiveConceptsAsStr)-1])\n",
    "fp.close()\n",
    "fp = open(gptNegativesPassTwoFilepath, \"x\")\n",
    "fp.write(negativeConceptsAsStr[:len(negativeConceptsAsStr)-1])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58aa506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0\n",
      "Specificity:  0.6933333333333334\n"
     ]
    }
   ],
   "source": [
    "#Combine the GPT-recommended concepts from pass one and pass two\n",
    "fpOne = open(gptPositivesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptPositivesPassTwoFilepath, \"r\")\n",
    "positivesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedPositiveConcepts = positivesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedPositiveConcepts = list(filter(None, proposedPositiveConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedPositiveConcepts = list(set(proposedPositiveConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedPositiveConcepts  = list(map(int, proposedPositiveConcepts))\n",
    "fpOne = open(gptNegativesPassOneFilepath, \"r\")\n",
    "fpTwo = open(gptNegativesPassTwoFilepath, \"r\")\n",
    "negativesAsStr = fpOne.readline() + \",\" + fpTwo.readline()\n",
    "fpOne.close()\n",
    "fpTwo.close()\n",
    "proposedNegativeConcepts = negativesAsStr.split(\",\")\n",
    "#Get rid of empty values from list\n",
    "proposedNegativeConcepts = list(filter(None, proposedNegativeConcepts))\n",
    "#Get only unique concept IDs\n",
    "proposedNegativeConcepts = list(set(proposedNegativeConcepts))\n",
    "#Convert concept IDs to integers\n",
    "proposedNegativeConcepts  = list(map(int, proposedNegativeConcepts))\n",
    "#Compute sensitivity and specificity\n",
    "phRes = compute_sens_and_spec(goldStandardPositives=goldStandardPositives, goldStandardNegatives=goldStandardNegatives, proposedPositives=proposedPositiveConcepts, proposedNegatives=proposedNegativeConcepts)\n",
    "print(\"Sensitivity: \", phRes[\"sensitivity\"])\n",
    "print(\"Specificity: \", phRes[\"specificity\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
